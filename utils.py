import pandas as pd
import csv
import numpy as np
from numpy.linalg import norm
from numpy import exp,sin,cos,pi
import ahrs
from ahrs import Quaternion


def load_endaq_log(prefix,t_min=0,t_max=3600,g=9.799):

    """
    Read in the cluster of CSV files that are autogenerated from the endaq proprietary analysis program
    The specific fields can be hard-coded since they wont.
    Make sure the configuration on the device is set to record these channels.
    Make sure that the accelerations are reported in m/s instead of g's

    t_filter = callable function to filter data based on time-values
    """

    raw_dat={}
    channels=[ \
        "Ch80_8g_DC_Acceleration.csv", \
        "Ch32_16g_DC_Acceleration.csv", \
        "Ch43_IMU_Acceleration.csv", \
        "Ch47_Rotation.csv", \
        "Ch51_IMU_Magnetic_Field.csv" ]

    raw_keys=[\
     "acc8", \
     "acc16", \
     "accIMU", \
     "gyro", \
     "mag"]

    for (ch,key) in zip(channels,raw_keys):
       # try:
            iter_csv=pd.read_csv(prefix+ch,chunksize=1000,names=["t","x","y","z"],\
                #index_col=1,
                #dtype={"t":pd.timedelta,"x":np.float64,"y":np.float64,"z":np.float64},\
                iterator=True,header=None)
            #raw_dat[key]=pd.read_csv(prefix+ch,header=None,names=["t","x","y","z"])
            raw_dat[key]=pd.concat([ chunk[ \
                            (chunk["t"] >= t_min) & (chunk["t"] <= t_max  )   ]  \
                            for chunk in iter_csv  \
                            ])
            ## Make the time column into the index
            raw_dat[key].index =pd.to_timedelta(raw_dat[key]['t'],unit="s")
            del raw_dat[key]['t']

       #     print("Successfully loaded ",ch)
       # except:
       #     print("Failed attempting to load ",ch)

    ##For some reason, the 8g accelerometer needs a factor of 2 correction on all 3 acceleration axes...
    ## It depends on the configuration

    ## Convert from units of g's to m/s^2 using a measurement of known local gravity
    for acc in ['acc8','acc16','accIMU']:
        if acc in raw_dat.keys():
            raw_dat[acc] = raw_dat[acc].apply(lambda q: q*g if q.name in ['x', 'y','z'] else q)

    return raw_dat

def subangle(v1,v2):
    """
    Compute the angle subtended between two vectors
    """
    return np.arccos(np.dot(v1,v2)/(norm(v1)*norm(v2)))


def R(lie_vec):
    """
    Compute the 3x3 rotation matrix from the lie generator
    """
    # Return the identity matrix if lie_vec=0
    if not np.any(lie_vec): return np.identity(3)
    ### Otherwise, compute axis-angle params

    angle=norm(lie_vec)/2
    n=lie_vec/norm(lie_vec)

    ###Construct the rotation matrix using the axis and angle
    c,s = cos(angle), sin(angle)
    x,y,z=n[0],n[1],n[2]
    return np.array([\
     [ c+x**2*(1-c),   x*y*(1-c)-z*s, x*z*(1-c)+y*s],\
     [ y*x*(1-c)+z*s,  c+y**2*(1-c),  y*z*(1-c)-x*s],\
     [ z*x*(1-c)-y*s,  z*y*(1-c)+x*s, c+z**2*(1-c) ]\
     ])

def axb2(a,b,sumall=True):
    """
    Vectorized wrapper for computing: (Sum) |axb|^2
    row index is the first index, as with drawing matrices on paper
    a,b = 3xN arrays

    Symmetry: f(a,b)=f(b,a)
    """
    if sumall:
        return np.sum(np.cross(a,b,axisa=0,axisb=0,axisc=0)**2)
    return np.sum(np.cross(a,b,axisa=0,axisb=0,axisc=0)**2,axis=0)



def alignment_cost(a,b):
    """
    Given a series of observed data, construct a const function which only has R as an arg
    """
    return lambda lie_params: axb2(a,R(lie_params).dot(b))


def lie_angle(lie_vec,unit="rad"):
    if unit=="rad":
        return norm(lie_vec)/2
    if unit=="deg":
        return (180/pi)*norm(lie_vec)/2


def cal_matrix(params):
    """
    params=[scale1,scale2,scale3 lie_vec1,lie_vec2,lie_vec3]
    """
    return R(params[3:6]).dot(np.diag(params[0:3]))

def calibration_cost(a,b):
    """
    |a-XRb|^2
    for a scale matrix X, rotation matrix R.
    params=[scale1,scale2,scale3 lie_vec1,lie_vec2,lie_vec3,offset1,offset2,offset3]
    """

    return lambda params: np.sum(( a- cal_matrix(params).dot(b)   )**2)



def synchronize_series(series,ref=None):
    """
    Resample data according to timestamps in a reference time series
    """
    if type(series) is not pd.DataFrame and type(series) is not pd.Series:
        raise TypeError("Input: series must be a pandas dataframe or time series")
    if type(ref) is not pd.DataFrame and type(ref) is not pd.Series:
        raise TypeError("Input: series must be a pandas dataframe or time series")
    return series.reindex(\
        series.index.union( ref.index     )\
        ).interpolate().loc[ref.index]


def idx_filter(t,data,intervals):
    """
    Filter the data inside the intervals
    params:
        t=[t1,t2,..,tn]
        data=[data1,data2,...,datan]
        intervals=[(a1,b1),(a2,b2),...]
    output:
        data[t in (a1,b1) or t in (a2,b2) ,...]
    """
    mask=np.array([False]*len(t))
    for interval in intervals:
        mask|= (interval[0]<t) & (t<interval[1])
    return t[mask],data[mask,:]



def apply_ahrs(gyro,acc,mag,ts,q0=np.array([1.0,0.0,0.0,0.0]) ,g=np.array([0,0,1])  ):
    """
    Measured value of local gravity is 9.799 m/s^2
    """
    assert len(gyro)==len(acc)
    assert len(acc)==len(mag)
    assert len(mag)==len(ts)

    try:
        q0=np.array(q0/np.linalg.norm(q0),dtype=np.float)
    except ValueError:
        raise ValueError("input q0 could not be coerced into an array of np.float")

    try:
        g=np.array(g,dtype=np.float)
    except ValueError:
        raise ValueError("input g could not be coerced into an array of np.float")

    assert len(q0)==4,"Input q0 must be length 4 to be considered a quaternion"
    assert len(g) ==3,"Input g must be length 3 to be a valid gravity vector"


    ## Compute the frequency and number of samples
    dt=np.mean(ts[1:]-ts[0:-1])
    freq=1/dt
    num_samples=len(ts)

    # Initialize the AHRS filter
    madgwick=ahrs.filters.Madgwick(beta=0.1,frequency=freq)

    # Allocate arrays using kwarg q0 as the initial reference orientation
    QMARG= np.tile(q0,(num_samples,1))
    QIMU=  np.tile(q0,(num_samples,1))
    ACC_LAB=np.zeros((num_samples,3))

    QIMU_quat=np.tile(Quaternion(q0),(num_samples,1))

    # For each time step apply the estimation filter
    for t in range(1,num_samples):

        # Orientation estimation using madwick filter
        QMARG[t]=madgwick.updateMARG(QMARG[t-1],gyro[t],acc[t],mag[t])
        QIMU[t]=madgwick.updateIMU(QIMU[t-1],gyro[t],acc[t])

        #For some reason QIMU is much better than QMARG
        QIMU_quat[t]=Quaternion(QIMU[t])
        #Rotate the acceleration vector from sensor frame to lab frame
        ACC_LAB[t]=Quaternion(QIMU[t]).rotate(acc[t])-g
    return ACC_LAB,QIMU_quat
